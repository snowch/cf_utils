{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- creates a MessageHub instance in Bluemix\n",
    "- produces some messages using vanilla python\n",
    "- consumes those messages using vanilla python\n",
    "- produces some more messages using vanilla python\n",
    "- consumes those messages using scala spark streaming\n",
    "- tears down the MessageHub instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First setup pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n",
      "Pixiedust version 0.58\n",
      "Package already installed: http://central.maven.org/maven2/org/apache/kafka/kafka-clients/0.9.0.0/kafka-clients-0.9.0.0.jar\n",
      "Package already installed: http://central.maven.org/maven2/org/apache/kafka/kafka_2.10/0.9.0.0/kafka_2.10-0.9.0.0.jar\n",
      "Package already installed: http://central.maven.org/maven2/org/apache/kafka/kafka-log4j-appender/0.9.0.0/kafka-log4j-appender-0.9.0.0.jar\n",
      "Package already installed: https://github.com/ibm-messaging/message-hub-samples/raw/master/java/message-hub-login-library/messagehub.login-1.0.0.jar\n",
      "Package already installed: https://github.com/ibm-messaging/iot-messgehub-spark-samples/releases/download/v0.1/streaming-kafka.jar\n",
      "\n",
      "** If this is the first time you have run this notebook, please restart the kernel and re-run this notebook now. **\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade --quiet pixiedust\n",
    "import pixiedust\n",
    "\n",
    "jars = [\"http://central.maven.org/maven2/org/apache/kafka/kafka-clients/0.9.0.0/kafka-clients-0.9.0.0.jar\",\n",
    "        \"http://central.maven.org/maven2/org/apache/kafka/kafka_2.10/0.9.0.0/kafka_2.10-0.9.0.0.jar\",\n",
    "        \"http://central.maven.org/maven2/org/apache/kafka/kafka-log4j-appender/0.9.0.0/kafka-log4j-appender-0.9.0.0.jar\",\n",
    "        \"https://github.com/ibm-messaging/message-hub-samples/raw/master/java/message-hub-login-library/messagehub.login-1.0.0.jar\",\n",
    "        \"https://github.com/ibm-messaging/iot-messgehub-spark-samples/releases/download/v0.1/streaming-kafka.jar\"]\n",
    "\n",
    "for j in jars:\n",
    "    pixiedust.installPackage(j)\n",
    "    \n",
    "print(\"\\n** If this is the first time you have run this notebook, please restart the kernel and re-run this notebook now. **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your bluemix ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM ID: chris.snow@uk.ibm.com\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "ibm_id = raw_input(\"IBM ID: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your bluemix ID password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password: ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "ibm_id_password = getpass(\"Password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup some variables that this notebook will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change this to point to your bluemix organization name\n",
    "bluemix_organization_name = 'chris.snow@uk.ibm.com'\n",
    "\n",
    "# change this to point to your bluemix space name\n",
    "bluemix_space_name = 'dev'\n",
    "\n",
    "# You may need to change the target_endpoint to:\n",
    "#\n",
    "#   https://api.ng.bluemix.net     - for the US South Region\n",
    "#   https://api.eu-gb.bluemix.net  - for the UK\n",
    "#   https://api.au-syd.bluemix.net - for Austrailia\n",
    "target_endpoint = 'https://api.ng.bluemix.net'\n",
    "\n",
    "# This is the name of the Message Hub service instance that will\n",
    "# be created for you in Bluemix\n",
    "messagehub_instance_name = 'my_messagehub'\n",
    "\n",
    "# This is the name of a topic that will get created for you\n",
    "messagehub_topic_name = 'my_topic'\n",
    "\n",
    "# Do you want to delete any existing MessageHub instance with\n",
    "# messagehub_instance_name for before creating a new one?\n",
    "delete_messagehub_instance = True\n",
    "\n",
    "# This is the guid of the Message Hub service plan. I found\n",
    "# this using:\n",
    "#\n",
    "#   cf = CloudFoundryUtil(target_endpoint, ibm_id, ibm_id_password)\n",
    "#   print(cf.search_plans('message hub'))\n",
    "mh_service_plan_guid = 'fe959ac5-aa47-43a6-9c58-6fc265ee9b0e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install a python utility script from github for interacting with cloud foundry via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: protobuf in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s85d-88ebffb000cc3e-39ca506ba762/.local/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: setuptools in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s85d-88ebffb000cc3e-39ca506ba762/.local/lib/python2.7/site-packages (from protobuf)\n",
      "Requirement already up-to-date: six>=1.9 in /usr/local/src/bluemix_jupyter_bundle.v22/notebook/lib/python2.7/site-packages (from protobuf)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade protobuf\n",
    "!pip install --user --upgrade --quiet git+https://github.com/snowch/cf_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python object for interacting with cloud foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cf_utils import cf_utils\n",
    "cf = cf_utils.CloudFoundryUtil(target_endpoint, ibm_id, ibm_id_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any MessageHub instances with the messagehub_instance_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if delete_messagehub_instance:\n",
    "    cf.delete_service(service_instance_name=messagehub_instance_name, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MessageHub service instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.create_service_instance(\n",
    "    bluemix_organization_name, \n",
    "    bluemix_space_name,\n",
    "    mh_service_plan_guid,\n",
    "    messagehub_instance_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract some variables that we will need to work with the MessageHub instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstrap_servers = cf.get_service_credential(messagehub_instance_name, 'kafka_brokers_sasl')\n",
    "# print(bootstrap_servers)\n",
    "\n",
    "sasl_username = cf.get_service_credential(messagehub_instance_name, 'user')\n",
    "# print(sasl_username)\n",
    "\n",
    "sasl_password = cf.get_service_credential(messagehub_instance_name, 'password')\n",
    "# print(sasl_password)\n",
    "\n",
    "api_key = cf.get_service_credential(messagehub_instance_name, 'api_key')\n",
    "# print(api_key)\n",
    "\n",
    "kafka_admin_url = cf.get_service_credential(messagehub_instance_name, 'kafka_admin_url')\n",
    "# print(kafka_admin_url)\n",
    "\n",
    "kafka_rest_url = cf.get_service_credential(messagehub_instance_name, 'kafka_rest_url')\n",
    "# print(kafka_rest_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a topic in the MessageHub instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"name\":\"my_topic\",\"partitions\":1,\"retentionMs\":\"86400000\",\"markedForDeletion\":false}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "data = { 'name' : messagehub_topic_name }\n",
    "headers = {\n",
    "    'content-type': 'application/json',\n",
    "    'X-Auth-Token' : api_key \n",
    "}\n",
    "url = kafka_admin_url + '/admin/topics'\n",
    "\n",
    "# create the topic (http POST)\n",
    "response = requests.post(url, headers = headers, data = json.dumps(data))\n",
    "\n",
    "# verify the topic was created (http GET)\n",
    "response = requests.get(url, headers = headers, data = json.dumps(data))\n",
    "print (response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install a python kafka client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --user --quiet kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a kafka producer and send some messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def produce_messages():\n",
    "    from kafka import KafkaProducer\n",
    "    from kafka.errors import KafkaError\n",
    "    import ssl\n",
    "\n",
    "    sasl_plain_username = sasl_username\n",
    "    sasl_plain_password = sasl_password \n",
    "\n",
    "    sasl_mechanism = 'PLAIN'\n",
    "    security_protocol = 'SASL_SSL'\n",
    "\n",
    "    # Create a new context using system defaults, disable all but TLS1.2\n",
    "    context = ssl.create_default_context()\n",
    "    context.options &= ssl.OP_NO_TLSv1\n",
    "    context.options &= ssl.OP_NO_TLSv1_1\n",
    "\n",
    "    producer = KafkaProducer(bootstrap_servers = bootstrap_servers,\n",
    "                             sasl_plain_username = sasl_plain_username,\n",
    "                             sasl_plain_password = sasl_plain_password,\n",
    "                             security_protocol = security_protocol,\n",
    "                             ssl_context = context,\n",
    "                             sasl_mechanism = sasl_mechanism,\n",
    "                             api_version = (0,10))\n",
    "\n",
    "    producer.send(messagehub_topic_name, b'some_raw_bytes_1')\n",
    "    producer.send(messagehub_topic_name, b'some_raw_bytes_2')\n",
    "\n",
    "    producer.flush()\n",
    "    \n",
    "produce_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a kafka consumer to consume the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_topic:0:0: key=None value=some_raw_bytes_1\n",
      "my_topic:0:1: key=None value=some_raw_bytes_2\n"
     ]
    }
   ],
   "source": [
    "def consume_messages():\n",
    "    from kafka import KafkaConsumer\n",
    "    from kafka.errors import KafkaError\n",
    "    import ssl\n",
    "\n",
    "    sasl_plain_username = sasl_username\n",
    "    sasl_plain_password = sasl_password \n",
    "\n",
    "    sasl_mechanism = 'PLAIN'\n",
    "    security_protocol = 'SASL_SSL'\n",
    "\n",
    "    # Create a new context using system defaults, disable all but TLS1.2\n",
    "    context = ssl.create_default_context()\n",
    "    context.options &= ssl.OP_NO_TLSv1\n",
    "    context.options &= ssl.OP_NO_TLSv1_1\n",
    "\n",
    "    consumer = KafkaConsumer(messagehub_topic_name,\n",
    "                             bootstrap_servers = bootstrap_servers,\n",
    "                             sasl_plain_username = sasl_plain_username,\n",
    "                             sasl_plain_password = sasl_plain_password,\n",
    "                             security_protocol = security_protocol,\n",
    "                             ssl_context = context,\n",
    "                             sasl_mechanism = sasl_mechanism,\n",
    "                             api_version = (0,10),\n",
    "                             consumer_timeout_ms = 10000,\n",
    "                             auto_offset_reset = 'earliest',\n",
    "                             group_id = \"python_client\")\n",
    "\n",
    "    for message in consumer:\n",
    "        print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "                                              message.offset, message.key,\n",
    "                                              message.value))\n",
    "\n",
    "consume_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the scala code expects a single string for the boostrap servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstrap_servers_string = ','.join(bootstrap_servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put some more messages in kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "produce_messages()\n",
    "produce_messages()\n",
    "produce_messages()\n",
    "produce_messages()\n",
    "produce_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the kafka spark streaming listener.<br><br>\n",
    "**Important:** If you run the below cell multiple times, always run the previous cell each time before you run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default location of ssl Trust store is: /usr/local/src/spark160master/ibm-java-x86_64-80/jre/lib/security/cacerts\n",
      "Registering JaasConfiguration: /gpfs/fs01/user/s85d-88ebffb000cc3e-39ca506ba762/notebook/tmp/Ve2C6SkrQBr5UYH1/jaas.conf\n",
      "group.id=5f33a695-80d4-4efe-8d48-3bc74c19d5ce\n",
      "default location of ssl Trust store is: /usr/local/src/spark160master/ibm-java-x86_64-80/jre/lib/security/cacerts\n",
      "-------------------------------------------\n",
      "Time: 1477916592000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916594000 ms\n",
      "-------------------------------------------\n",
      "(null,some_raw_bytes_1)\n",
      "(null,some_raw_bytes_2)\n",
      "(null,some_raw_bytes_1)\n",
      "(null,some_raw_bytes_2)\n",
      "(null,some_raw_bytes_1)\n",
      "(null,some_raw_bytes_2)\n",
      "(null,some_raw_bytes_1)\n",
      "(null,some_raw_bytes_2)\n",
      "(null,some_raw_bytes_1)\n",
      "(null,some_raw_bytes_2)\n",
      "-------------------------------------------\n",
      "Time: 1477916596000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916598000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916600000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916602000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916604000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916606000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916608000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916610000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916612000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916614000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916616000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916618000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916620000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916622000 ms\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Time: 1477916624000 ms\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%scala\n",
    "\n",
    "import org.apache.spark.streaming.Duration\n",
    "import org.apache.spark.streaming.Seconds\n",
    "import org.apache.spark.streaming.StreamingContext\n",
    "import com.ibm.cds.spark.samples.config.MessageHubConfig\n",
    "import com.ibm.cds.spark.samples.dstream.KafkaStreaming.KafkaStreamingContextAdapter\n",
    "import org.apache.kafka.common.serialization.Deserializer\n",
    "import org.apache.kafka.common.serialization.StringDeserializer\n",
    "import java.util.UUID\n",
    "\n",
    "val kafkaProps = new MessageHubConfig\n",
    "\n",
    "kafkaProps.setConfig(\"bootstrap.servers\",   bootstrap_servers_string.toString())\n",
    "kafkaProps.setConfig(\"kafka.user.name\",     sasl_username.toString())\n",
    "kafkaProps.setConfig(\"kafka.user.password\", sasl_password.toString())\n",
    "kafkaProps.setConfig(\"kafka.topic\",         messagehub_topic_name.toString())\n",
    "kafkaProps.setConfig(\"api_key\",             api_key.toString())\n",
    "kafkaProps.setConfig(\"kafka_rest_url\",      kafka_rest_url.toString())\n",
    "kafkaProps.setConfig(\"auto.offset.reset\",   \"earliest\") // should this be \"smallest\"?\n",
    "kafkaProps.setConfig(\"group.id\",            UUID.randomUUID().toString())\n",
    "\n",
    "kafkaProps.createConfiguration()\n",
    "\n",
    "// kafkaProps.toImmutableMap.foreach { keyVal => println(keyVal._1 + \"=\" + keyVal._2) }\n",
    "// println(\"group.id=\" + kafkaProps.getConfig(\"group.id\"))\n",
    "\n",
    "val ssc = new StreamingContext( sc, Seconds(2) )\n",
    "\n",
    "val stream = ssc.createKafkaStream[String, String, StringDeserializer, StringDeserializer](\n",
    "                     kafkaProps,\n",
    "                     List(kafkaProps.getConfig(\"kafka.topic\"))\n",
    "                     )\n",
    "stream.print()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTerminationOrTimeout(30000)\n",
    "ssc.stop(stopSparkContext=false, stopGracefully=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the MessageHub instance from Bluemix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if delete_messagehub_instance:\n",
    "    cf.delete_service(service_instance_name=messagehub_instance_name, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
